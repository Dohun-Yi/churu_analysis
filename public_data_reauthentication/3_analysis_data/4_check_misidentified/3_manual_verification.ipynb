{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42a7e6e-370a-4a60-b0dd-48e6b07126af",
   "metadata": {},
   "source": [
    "# Manual verification of misidentified data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268764d-7768-468e-8810-ca52eb3e6e74",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75464c59-bc10-4501-b073-716e3e85a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_root = '../../'\n",
    "path_workd = path_root + '/analysis/4_check_misidentified'\n",
    "\n",
    "dir_churu = path_workd + '/1697001520/output/'\n",
    "path_match = path_workd + '/1697001520.compare_result.before_verification.txt'\n",
    "path_meta = path_workd + '/1697001520.parse.filt.table'\n",
    "path_guess = path_workd + '/cellname_guesse_full.txt'\n",
    "path_cello = path_workd + '/cellosaurus.txt'\n",
    "path_cello_parsed = path_workd + '/cellosaurus.table.reform.acc.cvcl'\n",
    "path_institute = path_workd + '/institute_selected.parsed.corrected.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9a551a-72fe-4d54-85b3-0ca77e316ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cellosaurus data\n",
    "def get_lineage(child, child2parent):\n",
    "    # this dict contain information about \"originate from same individual\"\n",
    "    parents = child2parent.get(child,'').split('; ')\n",
    "    if [child] == parents:\n",
    "        return parents\n",
    "    else:\n",
    "        lst = [pp for p in parents for pp in get_lineage(p, child2parent)]\n",
    "        return parents + lst\n",
    "\n",
    "format_lineage = lambda x: list(set([x] + get_lineage(x, child2parent)) - set(['']))\n",
    "\n",
    "with open(path_cello_parsed) as f:\n",
    "    lines = f.readlines()\n",
    "    items = map(lambda x: x.rstrip('\\n').split('\\t'), lines)\n",
    "    child2parent = {x[0]:x[2] for x in items}\n",
    "    # child: [parent1, parent2, ... ]\n",
    "    child2lineage = {x:list(set(get_lineage(x, child2parent)) - set(['','-'])) for x in child2parent}\n",
    "    # child: [lineage1, lineage2, lineage3, ...]\n",
    "\n",
    "with open(path_cello) as f:\n",
    "    lines = f.readlines()\n",
    "    cell_id = ''\n",
    "    name2problems = {} # problematic\n",
    "    for line in lines:\n",
    "        line = line.rstrip('\\n')\n",
    "        if line.startswith('//'):\n",
    "            cell_id = ''\n",
    "        elif line.startswith('ID'):\n",
    "            cell_id = line.split('   ')[-1]\n",
    "            name2problems.setdefault(cell_id,[])\n",
    "        elif cell_id == '':\n",
    "            continue\n",
    "        elif line.startswith('CC'):\n",
    "            if 'problematic' in line.lower():\n",
    "                name2problems[cell_id].append(line.split('   ')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc337a7-f97a-44d8-b8f5-9c9d2b5f3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import authentication, guess data, institute data\n",
    "with open(path_match) as f:\n",
    "    lines = f.readlines()\n",
    "    items = map(lambda x: x.rstrip('\\n').split('\\t'), lines)\n",
    "    sam2match = {x[0]: x[1:] for x in items}\n",
    "    sam_mismatched = [k for k,v in sam2match.items() if v[2] == 'mismatch']\n",
    "    # sam: [call, claim, result]\n",
    "\n",
    "with open(path_guess) as f:\n",
    "    get_doc = lambda x: x['prompt1'].split('\\n    ')[2].lstrip('Given context to you: \"').rstrip('\"')\n",
    "    json_concat = json.load(f)\n",
    "    sam2guess = {k:v for json in json_concat for k, v in json.items()}\n",
    "    sam2doc = {k:get_doc(v) for k,v in sam2guess.items()}\n",
    "    # sam: {id:?, prompt1:?, gpt-4o-mini-response-1:?, cellosaurus-candidates:?, prompt2:? gpt-4o-mini-response-2:?, final-choice:?}\n",
    "\n",
    "with open(path_meta) as f:\n",
    "    lines = f.readlines()\n",
    "    items = map(lambda x: x.rstrip('\\n').split('\\t'), lines)\n",
    "    sam2srr = {x[10]:x[0] for x in items}\n",
    "    # sam: srr\n",
    "\n",
    "with open(path_institute) as f:\n",
    "    lines = f.readlines()\n",
    "    items = map(lambda x: x.rstrip('\\n').split('\\t'), lines)\n",
    "    sam2institute = {x[0]:x[1:] for x in items}\n",
    "    # sam: [owner, ror_id, institute, country, relation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a6a649-66fd-41c4-bc1e-0e11f73c46b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 5127/5127 [03:49<00:00, 22.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Import raw authentication data\n",
    "# This one takes some long time (2-3 minutes)\n",
    "sam2churu = {}\n",
    "for sam in tqdm(sam_mismatched): # only mismatched samples \n",
    "    path_churu = dir_churu + sam2srr[sam] + '/churu.out'\n",
    "    with open(path_churu) as f:\n",
    "        churu = list(map(lambda x: x.rstrip('\\n'), f.readlines()[1:]))\n",
    "    sam2churu[sam] = churu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72511eed-7d71-463f-a64e-54738ae091bb",
   "metadata": {},
   "source": [
    "### Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adfe7a39-b7b1-4959-88da-b3482759dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "format_red = \"\\x1b[1;30;41m%s\\x1b[m\"\n",
    "format_orange = \"\\x1b[1;30;43m%s\\x1b[m\"\n",
    "format_blue = \"\\x1b[1;30;44m%s\\x1b[m\"\n",
    "format_sky = \"\\x1b[1;30;46m%s\\x1b[m\"\n",
    "format_grey = \"\\x1b[1;31;47m%s\\x1b[m\"\n",
    "\n",
    "clean = lambda name: re.sub('\\W','',name).upper()\n",
    "\n",
    "def add_color(text, call, claim):\n",
    "    claim = re.sub(r'([\\[\\]])', r'\\\\\\1', claim)\n",
    "    call_clean, claim_clean = clean(call), clean(claim)\n",
    "    text = re.sub(call_clean, format_sky % call_clean, text, flags=re.IGNORECASE)\n",
    "    text = re.sub(claim_clean, format_orange % claim_clean, text, flags=re.IGNORECASE)\n",
    "    text = re.sub(call, format_blue % call, text, flags=re.IGNORECASE)\n",
    "    text = re.sub(claim, format_red % claim, text, flags=re.IGNORECASE)\n",
    "    # if nothing found in text, mark grey\n",
    "    if \"\\x1b\" not in text:\n",
    "        text = format_grey % text\n",
    "    return text\n",
    "\n",
    "def find_cell_from_churu(name, churu):\n",
    "    name2churu = {line.split('\\t')[1]:line for line in churu}\n",
    "    names_match = process.extract(name, list(name2churu.keys()), limit=2)\n",
    "    return [name2churu[n[0]] for n in names_match]\n",
    "\n",
    "def format_churu(churu, n_line=5):\n",
    "    return '\\n'.join(churu[:n_line])\n",
    "\n",
    "def format_problem(name, name2problem):\n",
    "    problems = name2problem[name]\n",
    "    if problems:\n",
    "        return f\"{name}: \\n\\t\" + '\\n\\t'.join(name2problem[name])\n",
    "    else:\n",
    "        return f\"{name}: \" + '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d177deb0-8c73-44aa-bb54-1245e21d4a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_likely_claim(claims, doc):\n",
    "    # return first mamtch\n",
    "    for claim in claims:\n",
    "        if re.findall(claim, doc, flags=re.IGNORECASE):\n",
    "            return claim\n",
    "    else: # if nothing found on claims, just return first one\n",
    "        return claims[0]\n",
    "\n",
    "def show_info(mysam):\n",
    "    text = ''\n",
    "    call, claim = sam2match[mysam][:2]\n",
    "    doc = sam2doc[mysam]\n",
    "    if '; ' in claim: # multiple guesses\n",
    "        text += '>>> Multiple guess case <<<' + '\\n'\n",
    "        text += format_red % claim + '\\n'\n",
    "        claims = claim.split('; ')\n",
    "        claim = pick_likely_claim(claims, doc)\n",
    "    churu = sam2churu[mysam]\n",
    "    churu_call = find_cell_from_churu(clean(call), churu)\n",
    "    churu_claim = find_cell_from_churu(clean(claim), churu)\n",
    "    text += \"=\"*10 + \" NAME  \" + \"=\"*10 + '\\n'\n",
    "    text += f\"call  : {format_blue % call}\" + '\\n'\n",
    "    text += f\"claim : {format_red % claim}\" + '\\n'\n",
    "    text += \"=\"*10 + \" LINE  \" + \"=\"*10 + '\\n'\n",
    "    text += add_color(' --> '.join(format_lineage(call)), call, claim) + '\\n'\n",
    "    text += add_color(' --> '.join(format_lineage(claim)), call, claim) + '\\n'\n",
    "    text += \"=\"*10 + \" PROB  \" + \"=\"*10 + '\\n'\n",
    "    text += add_color(format_problem(call, name2problems), call, claim) + '\\n'\n",
    "    text += add_color(format_problem(claim, name2problems), call, claim) + '\\n'\n",
    "    text += \"=\"*10 + \" DOC   \" + \"=\"*10 + '\\n'\n",
    "    text += add_color(doc, call, claim) + '\\n'\n",
    "    text += \"=\"*10 + \" TOP 5 \" + \"=\"*10 + '\\n'\n",
    "    text += add_color(format_churu(churu,5), call, claim) + '\\n'\n",
    "    text += \"=\"*10 + \" CALL  \" + \"=\"*10 + '\\n'\n",
    "    text += add_color(format_churu(churu_call, 2), call, claim) + '\\n'\n",
    "    text += \"=\"*10 + \" CLAIM \" + \"=\"*10 + '\\n'\n",
    "    text += add_color(format_churu(churu_claim, 2), call, claim) + '\\n'\n",
    "    text += \"=\"*27 + '\\n'\n",
    "    text += \"Checkpoint 1: is the claim in document?\" + '\\n'\n",
    "    text += \"Checkpoint 2: is the contamination supported by sufficient SNPs?\" + '\\n'\n",
    "    text += \"pass: '.', similar: 's', problematic: 'x', questionable: '?', not in CCLE: 'c'\" + '\\n'\n",
    "    text += \"=\"*27\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd159bec-5cf5-4ac9-a181-d1a74e18afc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== NAME  ==========\n",
      "call  : \u001b[1;30;44mHeLa\u001b[m\n",
      "claim : \u001b[1;30;41mMCF-7 TH\u001b[m\n",
      "========== LINE  ==========\n",
      "\u001b[1;30;46m\u001b[1;30;44mHeLa\u001b[m\u001b[m\n",
      "\u001b[1;30;41mMCF-7 TH\u001b[m --> OVCAR-8\n",
      "========== PROB  ==========\n",
      "\u001b[1;30;46m\u001b[1;30;44mHeLa\u001b[m\u001b[m: -\n",
      "\u001b[1;30;41mMCF-7 TH\u001b[m: \n",
      "\tProblematic cell line: Contaminated. Shown to be a OVCAR-8 derivative (PubMed=10995814). Originally thought to be a derivative of MCF-7.\n",
      "========== DOC   ==========\n",
      "\u001b[1;31;47msample id: SAMN15688113\n",
      "title: MCF-7T-2-IP\n",
      "sample name: -\n",
      "source_name: Breast cancer cells\n",
      "cell type: Breast cancer drug-resistant cells\n",
      "cell line: MCF-7/T\n",
      "treatment: treated with Taxol for 15 days\u001b[m\n",
      "========== TOP 5 ==========\n",
      "ACH-001086\t\u001b[1;30;46m\u001b[1;30;44mHeLa\u001b[m\u001b[m\tPT-c34xau\t11\t23.91%\t1.00\t-\n",
      "ACH-000794\tBICR22\tPT-zkbKhd\t4\t8.70%\t2.7e-21\t-\n",
      "ACH-000089\tNCIH684\tPT-0joF2E\t4\t8.70%\t2.7e-21\t-\n",
      "ACH-000271\tSUDHL10\tPT-i02i7U\t3\t6.52%\t6.5e-22\t-\n",
      "ACH-000914\tHT\tPT-zrYGap\t3\t6.52%\t6.5e-22\t-\n",
      "========== CALL  ==========\n",
      "ACH-001086\t\u001b[1;30;46m\u001b[1;30;44mHeLa\u001b[m\u001b[m\tPT-c34xau\t11\t23.91%\t1.00\t-\n",
      "ACH-000004\tHEL\tPT-q4K2cp\t1\t2.17%\t2.6e-35\t-\n",
      "========== CLAIM ==========\n",
      "\u001b[1;31;47mACH-000019\tMCF7\tPT-viJKnw\t1\t2.17%\t5.4e-31\t-\n",
      "ACH-000914\tHT\tPT-zrYGap\t3\t6.52%\t6.5e-22\t-\u001b[m\n",
      "===========================\n",
      "Checkpoint 1: is the claim in document?\n",
      "Checkpoint 2: is the contamination supported by sufficient SNPs?\n",
      "pass: '.', similar: 's', problematic: 'x', questionable: '?', not in CCLE: 'c'\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# mysam = random.choice(sam_mismatched)\n",
    "mysam = 'SAMN15688113'\n",
    "\n",
    "call, claim = sam2match[mysam][0:2]\n",
    "' --> '.join(format_lineage(call))\n",
    "\n",
    "# add_color(' --> '.join(format_lineage(call)), call, claim)\n",
    "print(show_info(mysam))\n",
    "# input('Your opinion: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "ed9f675b-7dc8-4d2b-8ec6-0e1153c9bb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 5127\n",
      "done: 5127\n",
      "left: 0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "output_txt = path_workd + '/manual_inspection_result.txt'\n",
    "output_log = path_workd + '/manual_inspection_result.log'\n",
    "\n",
    "sam_mismatched.sort()\n",
    "size = len(sam_mismatched)\n",
    "sam_done = set()\n",
    "if os.path.exists(output_txt):\n",
    "    with open(output_txt) as f:\n",
    "        lines = f.readlines()\n",
    "        sam_done = set([l.split('\\t')[0] for l in lines])\n",
    "\n",
    "sam_left = [sam for sam in sam_mismatched if sam not in sam_done]\n",
    "print(f\"total: {size}\")\n",
    "print(f\"done: {len(sam_done)}\")\n",
    "print(f\"left: {len(sam_left)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "1c3b26e6-d4c6-420d-8852-3a7097a35691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 266/266 [14:10<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "for mysam in tqdm(sam_left):\n",
    "    print(mysam)\n",
    "    tic = time.time()\n",
    "    text = show_info(mysam)\n",
    "    print(text)\n",
    "    response = input('Your response: ') or \"\"\n",
    "    toc = time.time()\n",
    "    time_took = f\"{toc - tic:.2f}sec\"\n",
    "    with open(output_txt, 'a') as f:\n",
    "        f.write(f\"{mysam}\\t{response}\\t{time_took}\\n\")\n",
    "    with open(output_log, 'a') as f:\n",
    "        f.write(f\">{mysam}\\n>{text}\\n>response:{response}\\ntime_took:{time_took}\\n\")\n",
    "    clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d99047d-02b2-4dbf-ad27-a4c5356e0f99",
   "metadata": {},
   "source": [
    "### second verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "591eebcf-114b-4298-8642-b5f3625714dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_proj = path_workd + '/SRA_churu_output_compare.1697001520.meta'\n",
    "with open(path_proj) as f:\n",
    "    items = map(lambda x: x.rstrip('\\n').split('\\t'), f.readlines())\n",
    "    sam2proj = {item[17]:item[18] for item in items}\n",
    "    proj2sam = {}\n",
    "    for sam, proj in sam2proj.items():\n",
    "        proj2sam.setdefault(proj,[]).append(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a69ff4b-2446-498a-aaf9-0cfe58500b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt = path_workd + '/manual_inspection_result.txt'\n",
    "output_txt = path_workd + '/manual_inspection_result.2.txt'\n",
    "\n",
    "counter = {}\n",
    "with open(input_txt) as f:\n",
    "    items_curation = list(map(lambda x: x.rstrip('\\n').split('\\t'), f.readlines()))\n",
    "    for _, curation, _ in items_curation:\n",
    "        counter.setdefault(curation,0)\n",
    "        counter[curation] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39487be0-9679-45f0-99e0-cbef4dbc1ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== NAME  ==========\n",
      "call  : \u001b[1;30;44mLNCaP clone FGC\u001b[m\n",
      "claim : \u001b[1;30;41mLB42\u001b[m\n",
      "========== LINE  ==========\n",
      "\u001b[1;30;44mLNCaP clone FGC\u001b[m --> LNCaP\n",
      "\u001b[1;30;43m\u001b[1;30;41mLB42\u001b[m\u001b[m\n",
      "========== PROB  ==========\n",
      "\u001b[1;30;44mLNCaP clone FGC\u001b[m: -\n",
      "\u001b[1;30;43m\u001b[1;30;41mLB42\u001b[m\u001b[m: -\n",
      "========== DOC   ==========\n",
      "\u001b[1;31;47msample id: SAMN08929693\n",
      "title: Sample_42Dplus\n",
      "sample name: -\n",
      "source_name: 42D\n",
      "rnase r treatment: yes\n",
      "treatment: N/A\n",
      "cell line: 42D\n",
      "cell type: prostate cancer cell line\u001b[m\n",
      "========== TOP 5 ==========\n",
      "ACH-000977\t\u001b[1;30;46mLNCAPCLONEFGC\u001b[m\tPT-tY34fU\t32\t94.12%\t1.00\t-\n",
      "ACH-001369\tOCIC5X\tPT-0GisSs\t1\t2.94%\t8.4e-26\t-\n",
      "ACH-002109\tES8\tPT-XwatVo\t1\t2.94%\t3.2e-26\t-\n",
      "ACH-000571\tT98G\tPT-dw7sni\t1\t2.94%\t1.3e-26\t-\n",
      "ACH-001610\tNP5\tPT-WoVaBP\t1\t2.94%\t9.1e-28\t-\n",
      "========== CALL  ==========\n",
      "ACH-000977\t\u001b[1;30;46mLNCAPCLONEFGC\u001b[m\tPT-tY34fU\t32\t94.12%\t1.00\t-\n",
      "ACH-000835\tGCT\tPT-0RBdNq\t0\t0.00%\t6.9e-30\t-\n",
      "========== CLAIM ==========\n",
      "\u001b[1;31;47mACH-002151\tLB2241RCC\tPT-hcnphT\t0\t0.00%\t6.9e-30\t-\n",
      "ACH-002152\tLB2518MEL\tPT-g7qDcx\t0\t0.00%\t6.9e-30\t-\u001b[m\n",
      "===========================\n",
      "Checkpoint 1: is the claim in document?\n",
      "Checkpoint 2: is the contamination supported by sufficient SNPs?\n",
      "pass: '.', similar: 's', problematic: 'x', questionable: '?', not in CCLE: 'c'\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "# check one by one\n",
    "mysam = 'SAMN08929693'\n",
    "print(show_info(mysam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffa448-788b-4b56-9220-9c8ca11c022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check one by one\n",
    "mysam = 'SAMN15582920'\n",
    "print(show_info(mysam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "6de6893b-fd48-40e7-8a99-2a4674469c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same project, different curation\n",
    "proj2curation = {}\n",
    "sam2curation = {}\n",
    "for sam, curation, _ in items_curation:\n",
    "    proj = sam2proj[sam]\n",
    "    proj2curation.setdefault(proj ,set()).add(curation)\n",
    "    sam2curation[sam] = curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "6561d26f-a598-49f8-b526-974988e34e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "tmp = 0\n",
    "for proj in proj2curation:\n",
    "    if len(proj2curation[proj]) != 1:\n",
    "        tmp += 1\n",
    "        # print(proj)\n",
    "        # print(proj2sam[proj])\n",
    "        # break\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "a63419e8-fef9-482d-8cf9-76b94ca0dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_input = [] # [ (sam, input), ... ]\n",
    "idx = 0\n",
    "project_with_multiple_curations = [proj for proj in proj2curation if len(proj2curation[proj]) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "57e12b10-646d-4888-b649-09409308a7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "PRJNA1004843\n",
      "['SAMN36955233', 'SAMN36955234', 'SAMN36955235', 'SAMN36955236', 'SAMN36955237', 'SAMN36955238']\n",
      "['?', '??', '?', '?', '?', '?']\n"
     ]
    }
   ],
   "source": [
    "idx += 1\n",
    "\n",
    "proj = project_with_multiple_curations[idx]\n",
    "sams = [sam for sam in proj2sam[proj] if sam in sam2curation]\n",
    "sams.sort()\n",
    "print(idx)\n",
    "print(proj)\n",
    "print(sams)\n",
    "print([sam2curation[sam] for sam in sams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "420e7785-af04-48cf-b682-49117a8237c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sam in sams:\n",
    "    print(show_info(sam))\n",
    "    print(sam2curation[sam])\n",
    "    input()\n",
    "    clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa65df7-9b20-482b-86cf-bc7763a9bc58",
   "metadata": {},
   "source": [
    "### HUVEC mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "0034774e-ba93-4d2b-a98b-906b8d4e3ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt = path_workd + '/manual_inspection_result.txt'\n",
    "output_txt = path_workd + '/manual_inspection_result.2.txt'\n",
    "\n",
    "counter = {}\n",
    "with open(input_txt) as f:\n",
    "    items_curation = list(map(lambda x: x.rstrip('\\n').split('\\t'), f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "8760094d-6c93-4643-9f39-473d98d89216",
   "metadata": {},
   "outputs": [],
   "source": [
    "sams_huvec = set()\n",
    "for sam in sam2match:\n",
    "    call, claim, _ = sam2match[sam]\n",
    "    if 'huvec' in claim.lower():\n",
    "        sams_huvec.add(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "d84163f6-a4c0-470d-9ca5-610321d84aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(items_curation)):\n",
    "    if items_curation[i][0] in sams_huvec:\n",
    "        items_curation[i][1] = 'huvec'\n",
    "with open(output_txt, 'w') as f:\n",
    "    lines_out = map(lambda x: '\\t'.join(x) + '\\t' + '\\t'.join(sam2match[x[0]]) + '\\n', items_curation)\n",
    "    f.writelines(lines_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c4037-ff8a-4eaf-9404-06a6ff8b2689",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(items_curation)):\n",
    "    sam, curation, _ = items_curation[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
